{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install Required Packages\n",
        "!pip install -q langchain_community langchain_huggingface \\\n",
        "               youtube-transcript-api faiss-cpu tiktoken \\\n",
        "               python-dotenv pymupdf pytube beautifulsoup4 wikipedia streamlit pyngrok"
      ],
      "metadata": {
        "id": "cFPi-jLx4yIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader, WikipediaLoader\n",
        "from langchain_community.document_loaders import YoutubeLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
        "import re\n",
        "import os\n",
        "import streamlit as st\n",
        "from pyngrok import ngrok\n"
      ],
      "metadata": {
        "id": "XltHLhD--eML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- CONFIG --------\n",
        "query = \"Nuclear Fusion\"\n",
        "pdf_path = None\n",
        "youtube_url = None"
      ],
      "metadata": {
        "id": "1pn6u-rqDMO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- LOADERS --------\n",
        "docs = []\n",
        "\n",
        "# Wikipedia is always used\n",
        "wiki_loader = WikipediaLoader(query=query,load_max_docs=17)\n",
        "wiki_docs = wiki_loader.load()\n",
        "for doc in wiki_docs:\n",
        "    doc.metadata[\"source\"] = f\"Wikipedia: {doc.metadata.get('title', 'Unknown')}\"\n",
        "docs.extend(wiki_docs)\n",
        "\n",
        "# Optional PDF\n",
        "if pdf_path:\n",
        "    try:\n",
        "        for doc in pdf_docs:\n",
        "          doc.metadata[\"source\"] = f\"PDF: {pdf_path}\"\n",
        "        docs.extend(pdf_docs)\n",
        "        print(\"‚úÖ PDF loaded\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è PDF loading failed: {e}\")\n",
        "\n",
        "# Optional YouTube\n",
        "if youtube_url:\n",
        "    match = re.search(r\"(?:v=|youtu.be/)([\\w-]+)\", youtube_url)\n",
        "    if match:\n",
        "        video_id = match.group(1)\n",
        "        try:\n",
        "            transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=[\"en\"])\n",
        "            transcript = \" \".join(chunk[\"text\"] for chunk in transcript_list)\n",
        "            doc = Document(page_content=transcript, metadata={\"source\": f\"YouTube: {youtube_url}\"})\n",
        "            docs.append(doc)\n",
        "            print(\"‚úÖ YouTube transcript loaded\")\n",
        "        except (TranscriptsDisabled, NoTranscriptFound):\n",
        "            print(\"‚ö†Ô∏è No usable English transcript found. Skipping video.\")\n",
        "        except Exception as e: # Catch other potential errors during retrieval/parsing\n",
        "            print(f\"‚ö†Ô∏è Error fetching or parsing YouTube transcript: {e}. Skipping video.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Invalid YouTube URL\")\n"
      ],
      "metadata": {
        "id": "PxnBUz0IBldy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- TEXT SPLITTING --------\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "split_docs = text_splitter.split_documents(docs[:5])\n",
        "print(f\"üîπ Total Chunks: {len(split_docs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8SZYl1iBsg4",
        "outputId": "0cbcad54-a59b-4672-b39c-489e864418e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Total Chunks: 63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- EMBEDDINGS --------\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vectors = FAISS.from_documents(split_docs, embeddings)\n",
        "retriever = vectors.as_retriever(search_type=\"similarity\", k=5)\n"
      ],
      "metadata": {
        "id": "80Z8A1LjCKde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- LLM --------\n",
        "from google.colab import userdata\n",
        "hf_api_token = userdata.get(\"huggingfacehub_api_token\")\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "    task=\"text-generation\",\n",
        "    huggingfacehub_api_token=hf_api_token\n",
        ")\n",
        "model = ChatHuggingFace(llm=llm)"
      ],
      "metadata": {
        "id": "dL6y86OlCN2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- PROMPT --------\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "    You are a helpful assistant.\n",
        "    Use the context below to answer the query, and reference sources using [number] format.\n",
        "    If the context is insufficient, just say you don't know.\n",
        "\n",
        "    {context}\n",
        "\n",
        "    Query: {query}\n",
        "    Answer:\n",
        "    \"\"\",\n",
        "    input_variables=[\"context\", \"query\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "Z1s3KN-CCRQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- CHAIN --------\n",
        "def format_docs_with_citations(docs):\n",
        "    formatted = []\n",
        "    for i, doc in enumerate(docs, 1):\n",
        "        source = doc.metadata.get(\"source\", \"Unknown source\")\n",
        "        formatted.append(f\"[{i}] {doc.page_content}\\n(Source: {source})\")\n",
        "    return \"\\n\\n\".join(formatted)\n",
        "\n",
        "\n",
        "parallel_chain = RunnableParallel({\n",
        "    \"context\": retriever | RunnableLambda(format_docs_with_citations),\n",
        "    \"query\": RunnablePassthrough()\n",
        "})\n",
        "\n",
        "final_chain = parallel_chain | prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "GYXz3mTUCUE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- EXECUTE --------\n",
        "answer = final_chain.invoke(query)\n",
        "print(\"\\n‚úÖ Final Answer:\\n\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOUS6YitCcyb",
        "outputId": "fa523efe-faed-44f3-81b6-eb3981f6c66b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Final Answer:\n",
            "  Nuclear fusion is a reaction in which atomic nuclei combine to form a larger nucleus, releasing energy due to the difference in nuclear binding energy before and after the fusion reaction [1]. It is the process that powers all active stars [1]. Applications of fusion include fusion power, thermonuclear weapons, boosted fission weapons, neutron sources, and superheavy element production [2]. The conditions required for fusion processes, such as a high temperature, density, and confinement time, are only found in stellar cores, advanced nuclear weapons, and fusion power experiments [4]. For a more detailed timeline of significant events in the study and use of nuclear fusion, refer to the timeline of nuclear fusion [3].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J_Kq0vVeKza_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}